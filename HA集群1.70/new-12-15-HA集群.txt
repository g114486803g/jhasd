#!/bin/bash

#建议先升级内核
wget https://github.com/g114486803g/k8s-/raw/master/HA%E9%9B%86%E7%BE%A41.70/update-kernel.sh
#关闭SELinux、防火墙
systemctl stop firewalld
systemctl disable firewalld
setenforce 0
sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config

#关闭系统的Swap

swapoff -a



# 安装ifconfig
yum install net-tools  ipvsadm ipset -y

# 时间同步
yum install -y ntpdate wget 

systemctl stop firewalld.service 
systemctl disable firewalld.service


cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

wget https://download.docker.com/linux/centos/docker-ce.repo -P /etc/yum.repos.d/

#安装包
yum install -y kubelet kubeadm kubectl
yum install -y docker-ce docker-ce-cli containerd.io

systemctl enable kubelet docker 
systemctl start docker 

#配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要


echo """
vm.swappiness = 0
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
""" > /etc/sysctl.conf
sysctl -p

#同步时间
ntpdate -u ntp1.aliyun.com

#开启IPVS（如果未升级内核，去掉ip_vs_fo）
cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr   ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo   ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack"
for kernel_module in \${ipvs_modules}; do
    /sbin/modinfo -F filename \${kernel_module} > /dev/null 2>&1
    if [ $? -eq 0 ]; then
        /sbin/modprobe \${kernel_module}
    fi
done
EOF

chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs

#所有机器需要设定/etc/sysctl.d/k8s.conf的系统参数
# https://github.com/moby/moby/issues/31208 
# ipvsadm -l --timeout
# 修复ipvs模式下长连接timeout问题 小于900即可
cat <<EOF > /etc/sysctl.d/k8s.conf
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 10
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
net.ipv4.neigh.default.gc_stale_time = 120
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.lo.arp_announce = 2
net.ipv4.conf.all.arp_announce = 2
net.ipv4.ip_forward = 1
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 1024
net.ipv4.tcp_synack_retries = 2
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.netfilter.nf_conntrack_max = 2310720
fs.inotify.max_user_watches=89100
fs.may_detach_mounts = 1
fs.file-max = 52706963
fs.nr_open = 52706963
net.bridge.bridge-nf-call-arptables = 1
vm.swappiness = 0
vm.overcommit_memory=1
vm.panic_on_oom=0
EOF

sysctl --system

######重启系统########
#reboot

#部署HAProxy Keepalived镜像下载
---------------------------------------------------
所有配置及脚本可以下载doc-all-12-15.zip解压即用
doc-all-12-15.zip
----------------------------------------------------
编辑haproxy.cfg文件

global
log 127.0.0.1 local0
log 127.0.0.1 local1 notice
maxconn 4096
#chroot /usr/share/haproxy
#user haproxy
#group haproxy
daemon

defaults
    log     global
    mode    http
    option  httplog
    option  dontlognull
    retries 3
    option redispatch
    timeout connect  5000
    timeout client  50000
    timeout server  50000

frontend stats-front
  bind *:8081
  mode http
  default_backend stats-back

frontend fe_k8s_6444
  bind *:6444
  mode tcp
  timeout client 1h
  log global
  option tcplog
  default_backend be_k8s_6443
  acl is_websocket hdr(Upgrade) -i WebSocket
  acl is_websocket hdr_beg(Host) -i ws

backend stats-back
  mode http
  balance roundrobin
  stats uri /haproxy/stats
  stats auth pxcstats:secret

backend be_k8s_6443
  mode tcp
  timeout queue 1h
  timeout server 1h
  timeout connect 1h
  log global
  balance roundrobin
  server rancher01 10.2.2.21:6443
  #server rancher02 10.2.2.22:6443
  #server rancher02 10.2.2.23:6443

#注意所有master第一次启动时只写本节点IP 
#######################################################
编译HAproxy脚本vim start-haproxy.sh

#!/bin/bash
MasterIP1=2.1.1.12
MasterIP2=2.1.1.31
MasterIP3=2.1.1.32
MasterPort=6443

docker run -d --restart=always --name HAProxy-K8S -p 6444:6444 \
        -e MasterIP1=$MasterIP1 \
        -e MasterIP2=$MasterIP2 \
        -e MasterIP3=$MasterIP3 \
        -e MasterPort=$MasterPort \
        -v /data/lb/etc/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg \
        wise2c/haproxy-k8s
		

##################################################################
编辑keepalived脚本 start-keepalived.sh
#!/bin/bash
VIRTUAL_IP=2.1.1.33  #VIP 的IP 我的是2.1.1.33
INTERFACE=ens32
NETMASK_BIT=24
CHECK_PORT=6444
RID=10
VRID=160
MCAST_GROUP=224.0.0.18

docker run -itd --restart=always --name=Keepalived-K8S \
        --net=host --cap-add=NET_ADMIN \
        -e VIRTUAL_IP=$VIRTUAL_IP \
        -e INTERFACE=$INTERFACE \
        -e CHECK_PORT=$CHECK_PORT \
        -e RID=$RID \
        -e VRID=$VRID \
        -e NETMASK_BIT=$NETMASK_BIT \
        -e MCAST_GROUP=$MCAST_GROUP \
        wise2c/keepalived-k8s

##############################################################
逐个启动
/data/lb/start-haproxy.sh
/data/lb/start-keepalived.sh

#####################
cd ~/
# 创建集群信息文件
echo """
CP0_IP=10.2.2.21
CP1_IP=10.2.2.22
CP2_IP=10.2.2.23
VIP=10.2.2.8
NET_IF=eth0
CIDR=10.244.0.0/16
""" > ./cluster-info

###################
echo """
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.17.0
controlPlaneEndpoint: "10.2.2.8:6444"
imageRepository: "registry.aliyuncs.com/google_containers"
networking:
  podSubnet: "10.244.0.0/16"
apiServer:
  certSANs:
  - ${CP0_IP}
  - ${CP1_IP}
  - ${CP2_IP}
  - ${VIP}

---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs
""" > /etc/kubernetes/jb.yaml

######################

#---我自己的如下-----


apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.17.0
controlPlaneEndpoint: "10.2.2.8:6444"
imageRepository: "registry.aliyuncs.com/google_containers"
networking:
  podSubnet: "10.244.0.0/16"
apiServer:
  certSANs:
  - "10.2.2.21"
  - "10.2.2.22"
  - "10.2.2.23"
  - "10.2.2.8"

---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs

-------------------------------------------------

#1.14.X版本之后不需要拷贝密钥只需要以下命令创建


kubeadm init --config=jb.yaml --upload-certs | tee bbcc.log

 kubeadm join 10.2.2.8:6444 --token m9vaqo.katw98kpwyn7g4ab \
    --discovery-token-ca-cert-hash sha256:c2dd6fb49ff42d9ecdb6ae9eb39d8539ff758c7c14c461b3645e04898a729ea1 \
    --control-plane --certificate-key 4b4e621ead36ce4c832e0ed893f7fecbc407d377da4a41a3061223a3a7647bad

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.2.2.8:6444 --token m9vaqo.katw98kpwyn7g4ab \
    --discovery-token-ca-cert-hash sha256:c2dd6fb49ff42d9ecdb6ae9eb39d8539ff758c7c14c461b3645e04898a729ea1 


--------------------------------------------
还没有完需要将haproxy.cfg 改成3个master节点的
  server rancher01 10.2.2.21:6443
  server rancher02 10.2.2.22:6443
  server rancher02 10.2.2.23:6443

重启doceker镜像生效


vim  $HOME/.kube/config
#将原来VIP地址和端口成本机的地址和端口
 #修改前 server:  https://10.2.2.8:6444  
#修改后  server: https://10.2.2.21:6443

https://www.kubernetes.org.cn/5163.html